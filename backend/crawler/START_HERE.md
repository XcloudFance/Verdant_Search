# ğŸ‰ çˆ¬è™«æ¨¡å—å·²ç‹¬ç«‹ï¼

## âœ¨ æ–°çš„ä½ç½®

çˆ¬è™«æ¨¡å—ç°åœ¨ä½äºï¼š**`backend/crawler/`**

è¿™æ˜¯ä¸€ä¸ªå®Œå…¨ç‹¬ç«‹çš„æ–‡ä»¶å¤¹ï¼ŒåŒ…å«æ‰€æœ‰çˆ¬è™«ç›¸å…³çš„æ–‡ä»¶ã€‚

## ğŸ“ ç›®å½•ç»“æ„

```
backend/
â”œâ”€â”€ crawler/              â† ğŸ•·ï¸ çˆ¬è™«æ¨¡å—ï¼ˆç‹¬ç«‹ï¼‰
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ crawler.py
â”‚   â”œâ”€â”€ url_manager.py
â”‚   â”œâ”€â”€ content_extractor.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ test_crawler.py
â”‚   â”œâ”€â”€ example_single_page.py
â”‚   â”œâ”€â”€ start_crawler.sh
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ OVERVIEW.md
â”‚   â”œâ”€â”€ QUICKSTART.md
â”‚   â””â”€â”€ ...
â”œâ”€â”€ python/               â† ğŸ” æœç´¢å¼•æ“API
â”‚   â”œâ”€â”€ index_service.py
â”‚   â”œâ”€â”€ search_service.py
â”‚   â””â”€â”€ ...
â””â”€â”€ go/                   â† ğŸš€ Go APIæœåŠ¡å™¨
    â””â”€â”€ ...
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. è¿›å…¥çˆ¬è™«ç›®å½•

```bash
cd /home/lancelot/verdant_search/backend/crawler
```

### 2. å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰

```bash
pip install -r requirements.txt
```

### 3. å¯åŠ¨çˆ¬è™«

**æ–¹æ³•A: ä½¿ç”¨å¯åŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰**
```bash
./start_crawler.sh
```

**æ–¹æ³•B: ç›´æ¥è¿è¡Œ**
```bash
python main.py --seeds https://www.python.org/
```

**æ–¹æ³•C: è‡ªå®šä¹‰é…ç½®**
```bash
python main.py --workers 20 --seeds https://www.python.org/ https://docs.python.org/
```

## ğŸ“Š å¸¸ç”¨å‘½ä»¤

æ‰€æœ‰å‘½ä»¤éƒ½åœ¨ `backend/crawler/` ç›®å½•ä¸‹è¿è¡Œï¼š

```bash
# æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
python main.py --stats

# æ¸…ç©ºçˆ¬è™«æ•°æ®
python main.py --clear

# æµ‹è¯•ç»„ä»¶
python test_crawler.py

# æµ‹è¯•å•ä¸ªé¡µé¢
python example_single_page.py https://www.python.org/
```

## âš™ï¸ é…ç½®

### ç¯å¢ƒå˜é‡

```bash
export CRAWLER_WORKERS=20      # å¹¶å‘è¿›ç¨‹æ•°
export CRAWLER_MAX_DEPTH=3     # æœ€å¤§æ·±åº¦
export REDIS_CRAWLER_DB=1      # Redisæ•°æ®åº“
```

### ä»£ç é…ç½®

ç¼–è¾‘ `config.py` æ–‡ä»¶ä¿®æ”¹ï¼š
- User-Agent
- è¯·æ±‚è¶…æ—¶
- é‡è¯•æ¬¡æ•°
- å†…å®¹é•¿åº¦é™åˆ¶
- URLè¿‡æ»¤è§„åˆ™

## ğŸ”— ä¸æœç´¢å¼•æ“é›†æˆ

çˆ¬è™«ä¼šè‡ªåŠ¨ï¼š
1. è°ƒç”¨ `backend/python/` çš„ç´¢å¼•æœåŠ¡
2. è¿›è¡Œåˆ†è¯å’Œå‘é‡ç¼–ç 
3. å­˜å‚¨åˆ° PostgreSQL æ•°æ®åº“
4. å¯é€šè¿‡æœç´¢å¼•æ“å‰ç«¯æŸ¥è¯¢

**æ— éœ€é¢å¤–é…ç½®ï¼**

## ğŸ“š æ–‡æ¡£

åœ¨ `backend/crawler/` ç›®å½•ä¸‹ï¼š

- ğŸ“– **README.md** - è¯¦ç»†ä½¿ç”¨æ–‡æ¡£
- ğŸ“ **OVERVIEW.md** - é¡¹ç›®æ¦‚è§ˆ
- ğŸš€ **QUICKSTART.md** - å¿«é€Ÿå…¥é—¨
- ğŸ“‹ **SUMMARY.md** - åŠŸèƒ½æ€»ç»“
- ğŸ”„ **MIGRATION.md** - è¿ç§»è¯´æ˜

## âœ… ä¼˜åŠ¿

1. **ç‹¬ç«‹æ¨¡å—** - æ‰€æœ‰çˆ¬è™«æ–‡ä»¶éƒ½åœ¨ä¸€ä¸ªæ–‡ä»¶å¤¹
2. **æ˜“äºç®¡ç†** - ä¸ä¸å…¶ä»–æ¨¡å—æ··åœ¨ä¸€èµ·
3. **ç‹¬ç«‹éƒ¨ç½²** - å¯ä»¥å•ç‹¬éƒ¨ç½²çˆ¬è™«æœåŠ¡
4. **æ¸…æ™°ç»“æ„** - ç›®å½•ç»“æ„æ›´åŠ æ¸…æ™°

## ğŸ¯ å¼€å§‹ä½¿ç”¨

```bash
cd /home/lancelot/verdant_search/backend/crawler
./start_crawler.sh
```

å°±è¿™ä¹ˆç®€å•ï¼ğŸŠ
